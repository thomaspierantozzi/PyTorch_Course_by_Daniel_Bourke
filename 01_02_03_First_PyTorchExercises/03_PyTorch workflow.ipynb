{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-13T21:58:40.240374Z",
     "start_time": "2025-02-13T21:58:40.237787Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T21:58:40.256206Z",
     "start_time": "2025-02-13T21:58:40.253682Z"
    }
   },
   "cell_type": "code",
   "source": "torch.__version__",
   "id": "f0813894b7897714",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Data preparing and loading...",
   "id": "ec04b6f6c70743d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T21:58:40.262649Z",
     "start_time": "2025-02-13T21:58:40.257923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "M = torch.tensor(data=[3 , 6, -0.04, -2.1], device='mps', dtype=torch.float).unsqueeze(1)\n",
    "Q = 15.6\n",
    "#let's prepare some synthetic data\n",
    "X = torch.randint(\n",
    "    low=-8,\n",
    "    high=27,\n",
    "    device='mps',\n",
    "    size=(50_000, 4),\n",
    "    dtype=torch.float\n",
    ")\n",
    "y = X @ M + Q\n",
    "\n",
    "print(f'Shape of tensor X: {X.shape} | Shape of tensor y: {y.shape}')"
   ],
   "id": "fb08294f48de9149",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor X: torch.Size([50000, 4]) | Shape of tensor y: torch.Size([50000, 1])\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T21:58:40.269408Z",
     "start_time": "2025-02-13T21:58:40.266750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_layer = nn.Linear(in_features=4, out_features=1, device='mps')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear_layer(x)\n",
    "        return x\n",
    "    \n",
    "linear_model = LinearRegression()"
   ],
   "id": "e544be5adc0ef438",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T21:59:00.635158Z",
     "start_time": "2025-02-13T21:58:40.270263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "PATIENCE = 25 #nr of iterations which must result in a loss lower than a given threshold, which the system must wait prior to stop the loop\n",
    "LOSS_DELTA_THRESHOLD = 1e-6\n",
    "MAX_ITERATIONS = 100_000\n",
    "iteration_converged = 0\n",
    "loss_foo = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(linear_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "loss_history=[]\n",
    "iteration = 0\n",
    "\n",
    "while True:\n",
    "    iteration += 1\n",
    "    prediction = linear_model(X) #forward step\n",
    "    step_loss = torch.sqrt(loss_foo(prediction, y))\n",
    "    loss_history.append(step_loss.item())\n",
    "    step_loss.backward() #computes the grad of the tensor, with respect to its varialbes where a requires_grad is set to True\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if iteration % 100 == 0:\n",
    "        print(f'Iteration: {iteration}, Loss: {step_loss.item():.5f}')\n",
    "    loss_delta = loss_history[-1] - loss_history[-2] if len(loss_history) > 5 else 1000\n",
    "    if abs(loss_delta) < LOSS_DELTA_THRESHOLD:\n",
    "        iteration_converged += 1\n",
    "    if (iteration_converged >= PATIENCE) or (iteration > MAX_ITERATIONS):\n",
    "        break\n",
    "        "
   ],
   "id": "5c5a263c8261f1ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100, Loss: 81.43188\n",
      "Iteration: 200, Loss: 58.03502\n",
      "Iteration: 300, Loss: 41.93195\n",
      "Iteration: 400, Loss: 30.57482\n",
      "Iteration: 500, Loss: 21.06225\n",
      "Iteration: 600, Loss: 13.00974\n",
      "Iteration: 700, Loss: 8.48117\n",
      "Iteration: 800, Loss: 7.59656\n",
      "Iteration: 900, Loss: 7.50445\n",
      "Iteration: 1000, Loss: 7.47590\n",
      "Iteration: 1100, Loss: 7.45154\n",
      "Iteration: 1200, Loss: 7.42746\n",
      "Iteration: 1300, Loss: 7.40340\n",
      "Iteration: 1400, Loss: 7.37934\n",
      "Iteration: 1500, Loss: 7.35528\n",
      "Iteration: 1600, Loss: 7.33121\n",
      "Iteration: 1700, Loss: 7.30715\n",
      "Iteration: 1800, Loss: 7.28308\n",
      "Iteration: 1900, Loss: 7.25902\n",
      "Iteration: 2000, Loss: 7.23495\n",
      "Iteration: 2100, Loss: 7.21089\n",
      "Iteration: 2200, Loss: 7.18683\n",
      "Iteration: 2300, Loss: 7.16276\n",
      "Iteration: 2400, Loss: 7.13870\n",
      "Iteration: 2500, Loss: 7.11464\n",
      "Iteration: 2600, Loss: 7.09058\n",
      "Iteration: 2700, Loss: 7.06652\n",
      "Iteration: 2800, Loss: 7.04246\n",
      "Iteration: 2900, Loss: 7.01840\n",
      "Iteration: 3000, Loss: 6.99433\n",
      "Iteration: 3100, Loss: 6.97027\n",
      "Iteration: 3200, Loss: 6.94621\n",
      "Iteration: 3300, Loss: 6.92215\n",
      "Iteration: 3400, Loss: 6.89809\n",
      "Iteration: 3500, Loss: 6.87403\n",
      "Iteration: 3600, Loss: 6.84997\n",
      "Iteration: 3700, Loss: 6.82591\n",
      "Iteration: 3800, Loss: 6.80184\n",
      "Iteration: 3900, Loss: 6.77778\n",
      "Iteration: 4000, Loss: 6.75372\n",
      "Iteration: 4100, Loss: 6.72966\n",
      "Iteration: 4200, Loss: 6.70560\n",
      "Iteration: 4300, Loss: 6.68154\n",
      "Iteration: 4400, Loss: 6.65747\n",
      "Iteration: 4500, Loss: 6.63341\n",
      "Iteration: 4600, Loss: 6.60934\n",
      "Iteration: 4700, Loss: 6.58527\n",
      "Iteration: 4800, Loss: 6.56120\n",
      "Iteration: 4900, Loss: 6.53714\n",
      "Iteration: 5000, Loss: 6.51307\n",
      "Iteration: 5100, Loss: 6.48900\n",
      "Iteration: 5200, Loss: 6.46494\n",
      "Iteration: 5300, Loss: 6.44087\n",
      "Iteration: 5400, Loss: 6.41680\n",
      "Iteration: 5500, Loss: 6.39273\n",
      "Iteration: 5600, Loss: 6.36867\n",
      "Iteration: 5700, Loss: 6.34460\n",
      "Iteration: 5800, Loss: 6.32053\n",
      "Iteration: 5900, Loss: 6.29647\n",
      "Iteration: 6000, Loss: 6.27240\n",
      "Iteration: 6100, Loss: 6.24833\n",
      "Iteration: 6200, Loss: 6.22426\n",
      "Iteration: 6300, Loss: 6.20020\n",
      "Iteration: 6400, Loss: 6.17613\n",
      "Iteration: 6500, Loss: 6.15206\n",
      "Iteration: 6600, Loss: 6.12800\n",
      "Iteration: 6700, Loss: 6.10393\n",
      "Iteration: 6800, Loss: 6.07986\n",
      "Iteration: 6900, Loss: 6.05580\n",
      "Iteration: 7000, Loss: 6.03173\n",
      "Iteration: 7100, Loss: 6.00766\n",
      "Iteration: 7200, Loss: 5.98359\n",
      "Iteration: 7300, Loss: 5.95953\n",
      "Iteration: 7400, Loss: 5.93546\n",
      "Iteration: 7500, Loss: 5.91139\n",
      "Iteration: 7600, Loss: 5.88732\n",
      "Iteration: 7700, Loss: 5.86326\n",
      "Iteration: 7800, Loss: 5.83919\n",
      "Iteration: 7900, Loss: 5.81512\n",
      "Iteration: 8000, Loss: 5.79106\n",
      "Iteration: 8100, Loss: 5.76699\n",
      "Iteration: 8200, Loss: 5.74292\n",
      "Iteration: 8300, Loss: 5.71886\n",
      "Iteration: 8400, Loss: 5.69479\n",
      "Iteration: 8500, Loss: 5.67072\n",
      "Iteration: 8600, Loss: 5.64665\n",
      "Iteration: 8700, Loss: 5.62259\n",
      "Iteration: 8800, Loss: 5.59852\n",
      "Iteration: 8900, Loss: 5.57445\n",
      "Iteration: 9000, Loss: 5.55039\n",
      "Iteration: 9100, Loss: 5.52632\n",
      "Iteration: 9200, Loss: 5.50225\n",
      "Iteration: 9300, Loss: 5.47818\n",
      "Iteration: 9400, Loss: 5.45412\n",
      "Iteration: 9500, Loss: 5.43005\n",
      "Iteration: 9600, Loss: 5.40598\n",
      "Iteration: 9700, Loss: 5.38192\n",
      "Iteration: 9800, Loss: 5.35785\n",
      "Iteration: 9900, Loss: 5.33378\n",
      "Iteration: 10000, Loss: 5.30972\n",
      "Iteration: 10100, Loss: 5.28565\n",
      "Iteration: 10200, Loss: 5.26158\n",
      "Iteration: 10300, Loss: 5.23751\n",
      "Iteration: 10400, Loss: 5.21345\n",
      "Iteration: 10500, Loss: 5.18938\n",
      "Iteration: 10600, Loss: 5.16531\n",
      "Iteration: 10700, Loss: 5.14125\n",
      "Iteration: 10800, Loss: 5.11718\n",
      "Iteration: 10900, Loss: 5.09311\n",
      "Iteration: 11000, Loss: 5.06904\n",
      "Iteration: 11100, Loss: 5.04498\n",
      "Iteration: 11200, Loss: 5.02091\n",
      "Iteration: 11300, Loss: 4.99684\n",
      "Iteration: 11400, Loss: 4.97278\n",
      "Iteration: 11500, Loss: 4.94871\n",
      "Iteration: 11600, Loss: 4.92464\n",
      "Iteration: 11700, Loss: 4.90057\n",
      "Iteration: 11800, Loss: 4.87651\n",
      "Iteration: 11900, Loss: 4.85244\n",
      "Iteration: 12000, Loss: 4.82837\n",
      "Iteration: 12100, Loss: 4.80431\n",
      "Iteration: 12200, Loss: 4.78024\n",
      "Iteration: 12300, Loss: 4.75617\n",
      "Iteration: 12400, Loss: 4.73210\n",
      "Iteration: 12500, Loss: 4.70804\n",
      "Iteration: 12600, Loss: 4.68397\n",
      "Iteration: 12700, Loss: 4.65990\n",
      "Iteration: 12800, Loss: 4.63584\n",
      "Iteration: 12900, Loss: 4.61177\n",
      "Iteration: 13000, Loss: 4.58770\n",
      "Iteration: 13100, Loss: 4.56364\n",
      "Iteration: 13200, Loss: 4.53957\n",
      "Iteration: 13300, Loss: 4.51550\n",
      "Iteration: 13400, Loss: 4.49143\n",
      "Iteration: 13500, Loss: 4.46737\n",
      "Iteration: 13600, Loss: 4.44330\n",
      "Iteration: 13700, Loss: 4.41923\n",
      "Iteration: 13800, Loss: 4.39517\n",
      "Iteration: 13900, Loss: 4.37110\n",
      "Iteration: 14000, Loss: 4.34703\n",
      "Iteration: 14100, Loss: 4.32296\n",
      "Iteration: 14200, Loss: 4.29890\n",
      "Iteration: 14300, Loss: 4.27483\n",
      "Iteration: 14400, Loss: 4.25076\n",
      "Iteration: 14500, Loss: 4.22670\n",
      "Iteration: 14600, Loss: 4.20263\n",
      "Iteration: 14700, Loss: 4.17856\n",
      "Iteration: 14800, Loss: 4.15449\n",
      "Iteration: 14900, Loss: 4.13043\n",
      "Iteration: 15000, Loss: 4.10636\n",
      "Iteration: 15100, Loss: 4.08229\n",
      "Iteration: 15200, Loss: 4.05823\n",
      "Iteration: 15300, Loss: 4.03416\n",
      "Iteration: 15400, Loss: 4.01009\n",
      "Iteration: 15500, Loss: 3.98602\n",
      "Iteration: 15600, Loss: 3.96196\n",
      "Iteration: 15700, Loss: 3.93789\n",
      "Iteration: 15800, Loss: 3.91382\n",
      "Iteration: 15900, Loss: 3.88976\n",
      "Iteration: 16000, Loss: 3.86569\n",
      "Iteration: 16100, Loss: 3.84162\n",
      "Iteration: 16200, Loss: 3.81756\n",
      "Iteration: 16300, Loss: 3.79349\n",
      "Iteration: 16400, Loss: 3.76942\n",
      "Iteration: 16500, Loss: 3.74535\n",
      "Iteration: 16600, Loss: 3.72129\n",
      "Iteration: 16700, Loss: 3.69722\n",
      "Iteration: 16800, Loss: 3.67315\n",
      "Iteration: 16900, Loss: 3.64909\n",
      "Iteration: 17000, Loss: 3.62502\n",
      "Iteration: 17100, Loss: 3.60095\n",
      "Iteration: 17200, Loss: 3.57688\n",
      "Iteration: 17300, Loss: 3.55282\n",
      "Iteration: 17400, Loss: 3.52875\n",
      "Iteration: 17500, Loss: 3.50468\n",
      "Iteration: 17600, Loss: 3.48062\n",
      "Iteration: 17700, Loss: 3.45655\n",
      "Iteration: 17800, Loss: 3.43248\n",
      "Iteration: 17900, Loss: 3.40842\n",
      "Iteration: 18000, Loss: 3.38435\n",
      "Iteration: 18100, Loss: 3.36028\n",
      "Iteration: 18200, Loss: 3.33621\n",
      "Iteration: 18300, Loss: 3.31215\n",
      "Iteration: 18400, Loss: 3.28808\n",
      "Iteration: 18500, Loss: 3.26401\n",
      "Iteration: 18600, Loss: 3.23994\n",
      "Iteration: 18700, Loss: 3.21588\n",
      "Iteration: 18800, Loss: 3.19181\n",
      "Iteration: 18900, Loss: 3.16774\n",
      "Iteration: 19000, Loss: 3.14368\n",
      "Iteration: 19100, Loss: 3.11961\n",
      "Iteration: 19200, Loss: 3.09554\n",
      "Iteration: 19300, Loss: 3.07148\n",
      "Iteration: 19400, Loss: 3.04741\n",
      "Iteration: 19500, Loss: 3.02334\n",
      "Iteration: 19600, Loss: 2.99927\n",
      "Iteration: 19700, Loss: 2.97521\n",
      "Iteration: 19800, Loss: 2.95114\n",
      "Iteration: 19900, Loss: 2.92707\n",
      "Iteration: 20000, Loss: 2.90301\n",
      "Iteration: 20100, Loss: 2.87894\n",
      "Iteration: 20200, Loss: 2.85487\n",
      "Iteration: 20300, Loss: 2.83080\n",
      "Iteration: 20400, Loss: 2.80674\n",
      "Iteration: 20500, Loss: 2.78267\n",
      "Iteration: 20600, Loss: 2.75860\n",
      "Iteration: 20700, Loss: 2.73454\n",
      "Iteration: 20800, Loss: 2.71047\n",
      "Iteration: 20900, Loss: 2.68640\n",
      "Iteration: 21000, Loss: 2.66233\n",
      "Iteration: 21100, Loss: 2.63827\n",
      "Iteration: 21200, Loss: 2.61420\n",
      "Iteration: 21300, Loss: 2.59013\n",
      "Iteration: 21400, Loss: 2.56607\n",
      "Iteration: 21500, Loss: 2.54200\n",
      "Iteration: 21600, Loss: 2.51793\n",
      "Iteration: 21700, Loss: 2.49387\n",
      "Iteration: 21800, Loss: 2.46980\n",
      "Iteration: 21900, Loss: 2.44573\n",
      "Iteration: 22000, Loss: 2.42166\n",
      "Iteration: 22100, Loss: 2.39760\n",
      "Iteration: 22200, Loss: 2.37353\n",
      "Iteration: 22300, Loss: 2.34946\n",
      "Iteration: 22400, Loss: 2.32540\n",
      "Iteration: 22500, Loss: 2.30133\n",
      "Iteration: 22600, Loss: 2.27726\n",
      "Iteration: 22700, Loss: 2.25319\n",
      "Iteration: 22800, Loss: 2.22913\n",
      "Iteration: 22900, Loss: 2.20506\n",
      "Iteration: 23000, Loss: 2.18099\n",
      "Iteration: 23100, Loss: 2.15693\n",
      "Iteration: 23200, Loss: 2.13286\n",
      "Iteration: 23300, Loss: 2.10879\n",
      "Iteration: 23400, Loss: 2.08472\n",
      "Iteration: 23500, Loss: 2.06066\n",
      "Iteration: 23600, Loss: 2.03659\n",
      "Iteration: 23700, Loss: 2.01252\n",
      "Iteration: 23800, Loss: 1.98846\n",
      "Iteration: 23900, Loss: 1.96439\n",
      "Iteration: 24000, Loss: 1.94032\n",
      "Iteration: 24100, Loss: 1.91626\n",
      "Iteration: 24200, Loss: 1.89219\n",
      "Iteration: 24300, Loss: 1.86812\n",
      "Iteration: 24400, Loss: 1.84405\n",
      "Iteration: 24500, Loss: 1.81999\n",
      "Iteration: 24600, Loss: 1.79592\n",
      "Iteration: 24700, Loss: 1.77185\n",
      "Iteration: 24800, Loss: 1.74779\n",
      "Iteration: 24900, Loss: 1.72372\n",
      "Iteration: 25000, Loss: 1.69965\n",
      "Iteration: 25100, Loss: 1.67558\n",
      "Iteration: 25200, Loss: 1.65152\n",
      "Iteration: 25300, Loss: 1.62745\n",
      "Iteration: 25400, Loss: 1.60338\n",
      "Iteration: 25500, Loss: 1.57932\n",
      "Iteration: 25600, Loss: 1.55525\n",
      "Iteration: 25700, Loss: 1.53118\n",
      "Iteration: 25800, Loss: 1.50711\n",
      "Iteration: 25900, Loss: 1.48305\n",
      "Iteration: 26000, Loss: 1.45898\n",
      "Iteration: 26100, Loss: 1.43491\n",
      "Iteration: 26200, Loss: 1.41085\n",
      "Iteration: 26300, Loss: 1.38678\n",
      "Iteration: 26400, Loss: 1.36271\n",
      "Iteration: 26500, Loss: 1.33865\n",
      "Iteration: 26600, Loss: 1.31458\n",
      "Iteration: 26700, Loss: 1.29051\n",
      "Iteration: 26800, Loss: 1.26644\n",
      "Iteration: 26900, Loss: 1.24238\n",
      "Iteration: 27000, Loss: 1.21831\n",
      "Iteration: 27100, Loss: 1.19424\n",
      "Iteration: 27200, Loss: 1.17018\n",
      "Iteration: 27300, Loss: 1.14611\n",
      "Iteration: 27400, Loss: 1.12204\n",
      "Iteration: 27500, Loss: 1.09797\n",
      "Iteration: 27600, Loss: 1.07391\n",
      "Iteration: 27700, Loss: 1.04984\n",
      "Iteration: 27800, Loss: 1.02577\n",
      "Iteration: 27900, Loss: 1.00171\n",
      "Iteration: 28000, Loss: 0.97764\n",
      "Iteration: 28100, Loss: 0.95357\n",
      "Iteration: 28200, Loss: 0.92950\n",
      "Iteration: 28300, Loss: 0.90544\n",
      "Iteration: 28400, Loss: 0.88137\n",
      "Iteration: 28500, Loss: 0.85730\n",
      "Iteration: 28600, Loss: 0.83324\n",
      "Iteration: 28700, Loss: 0.80917\n",
      "Iteration: 28800, Loss: 0.78510\n",
      "Iteration: 28900, Loss: 0.76103\n",
      "Iteration: 29000, Loss: 0.73697\n",
      "Iteration: 29100, Loss: 0.71290\n",
      "Iteration: 29200, Loss: 0.68883\n",
      "Iteration: 29300, Loss: 0.66477\n",
      "Iteration: 29400, Loss: 0.64070\n",
      "Iteration: 29500, Loss: 0.61663\n",
      "Iteration: 29600, Loss: 0.59256\n",
      "Iteration: 29700, Loss: 0.56850\n",
      "Iteration: 29800, Loss: 0.54443\n",
      "Iteration: 29900, Loss: 0.52036\n",
      "Iteration: 30000, Loss: 0.49630\n",
      "Iteration: 30100, Loss: 0.47223\n",
      "Iteration: 30200, Loss: 0.44816\n",
      "Iteration: 30300, Loss: 0.42410\n",
      "Iteration: 30400, Loss: 0.40003\n",
      "Iteration: 30500, Loss: 0.37596\n",
      "Iteration: 30600, Loss: 0.35189\n",
      "Iteration: 30700, Loss: 0.32783\n",
      "Iteration: 30800, Loss: 0.30376\n",
      "Iteration: 30900, Loss: 0.27969\n",
      "Iteration: 31000, Loss: 0.25563\n",
      "Iteration: 31100, Loss: 0.23156\n",
      "Iteration: 31200, Loss: 0.20749\n",
      "Iteration: 31300, Loss: 0.21221\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T21:59:00.643278Z",
     "start_time": "2025-02-13T21:59:00.635683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Number of iterations: ', iteration)\n",
    "for param_value, param in zip(linear_model.parameters(), ['weights', 'bias']):\n",
    "    print(f'{param}: {param_value}')\n",
    "\n",
    "print(f'\\nRMSE_Loss: {np.sqrt(loss_history[-1]):.4f}')"
   ],
   "id": "c858696ce0d13933",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations:  31394\n",
      "weights: Parameter containing:\n",
      "tensor([[ 3.0039,  6.0038, -0.0362, -2.0961]], device='mps:0',\n",
      "       requires_grad=True)\n",
      "bias: Parameter containing:\n",
      "tensor([15.2635], device='mps:0', requires_grad=True)\n",
      "\n",
      "RMSE_Loss: 0.4609\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T21:59:00.679122Z",
     "start_time": "2025-02-13T21:59:00.644335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.plot(loss_history,\n",
    "         linewidth=0.5,)"
   ],
   "id": "810497c8346cc8c5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x158ec8920>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T21:59:00.681706Z",
     "start_time": "2025-02-13T21:59:00.679674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_test = torch.randint(\n",
    "    low=-8,\n",
    "    high=27,\n",
    "    device='mps',\n",
    "    size=(10_000, 4),\n",
    "    dtype=torch.float\n",
    ")\n",
    "y_test = X_test @ M + Q"
   ],
   "id": "6344e476e51d8f3e",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T21:59:00.685429Z",
     "start_time": "2025-02-13T21:59:00.682287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "linear_model.eval()\n",
    "with torch.inference_mode():\n",
    "    y_pred_test = linear_model(X_test)\n",
    "print(f'Shape of y_pred_test: {y_pred_test.shape} | Shape of y_test: {y_test.shape}')\n",
    "rmse = torch.sqrt(loss_foo(y_pred_test, y_test))\n",
    "print(f'RMSE on test set: {rmse:.4f}')"
   ],
   "id": "ac5dce64323e2806",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_pred_test: torch.Size([10000, 1]) | Shape of y_test: torch.Size([10000, 1])\n",
      "RMSE on test set: 0.2122\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T21:59:00.687111Z",
     "start_time": "2025-02-13T21:59:00.686013Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "af8539c2d597b704",
   "outputs": [],
   "execution_count": 56
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
