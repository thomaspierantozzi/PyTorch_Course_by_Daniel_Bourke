{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T11:46:52.187615Z",
     "start_time": "2025-02-10T11:46:52.184914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import tensorflow as tf \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "id": "4fc81251c6f93c27",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T11:46:52.259489Z",
     "start_time": "2025-02-10T11:46:52.188717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Importo i dati dalla libreria MNIST integrata in keras\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(f'X_train shape: {X_train.shape}, type: {type(X_train)}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')"
   ],
   "id": "c645d358ae439e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28), type: <class 'numpy.ndarray'>\n",
      "y_train shape: (60000,)\n",
      "X_test shape: (10000, 28, 28)\n",
      "y_test shape: (10000,)\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T11:46:52.273656Z",
     "start_time": "2025-02-10T11:46:52.260327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a TensorDataset object from the data\n",
    "dataset = TensorDataset(torch.from_numpy(X_train, ).to(torch.float), torch.from_numpy(y_train).to(torch.float))\n",
    "dataset_test = TensorDataset(torch.from_numpy(X_test, ).to(torch.float), torch.from_numpy(y_test).to(torch.float))\n",
    "# Create a DataLoader object with batch size 32\n",
    "batch_size = 600\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ],
   "id": "6211e7192f00bdec",
   "outputs": [],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T11:46:52.276583Z",
     "start_time": "2025-02-10T11:46:52.274254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConvNet(nn.Module):\n",
    "    '''\n",
    "    definition of a convolutional network in Pytorch\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels= 20, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=20, out_channels= 30, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=30, out_channels= 50, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(in_features=50 * 7 * 7, out_features=600)\n",
    "        self.fc2 = nn.Linear(in_features=600, out_features=10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.relu(self.conv3(X))\n",
    "        X = torch.flatten(X, 1)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = self.fc2(X)\n",
    "        return X\n"
   ],
   "id": "a0b2e6f96500948a",
   "outputs": [],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T11:46:52.301951Z",
     "start_time": "2025-02-10T11:46:52.277948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('mps' if torch.mps.is_available() else 'cpu')\n",
    "conv_nn = ConvNet().to(device)\n",
    "print(f'The device used is: {device}')"
   ],
   "id": "6fce5723be920c66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device used is: mps\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T11:46:52.304745Z",
     "start_time": "2025-02-10T11:46:52.302663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(conv_nn.parameters(), lr=learning_rate)"
   ],
   "id": "a338a4a13392b070",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T11:48:19.355846Z",
     "start_time": "2025-02-10T11:46:52.305250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 50\n",
    "n_total_steps = len(dataloader)\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "#        print(type(images))\n",
    "        images = images.reshape(batch_size, 1, 28, 28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = conv_nn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'[{epoch + 1}] loss: {running_loss / n_total_steps:.6f}')\n",
    "\n",
    "print('Finished Training')\n",
    "PATH = './cnn.pth'\n",
    "torch.save(conv_nn.state_dict(), PATH)"
   ],
   "id": "14119cb3fa988257",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 0.374345\n",
      "[2] loss: 0.106332\n",
      "[3] loss: 0.067450\n",
      "[4] loss: 0.047710\n",
      "[5] loss: 0.035680\n",
      "[6] loss: 0.028083\n",
      "[7] loss: 0.021298\n",
      "[8] loss: 0.017351\n",
      "[9] loss: 0.012741\n",
      "[10] loss: 0.010492\n",
      "[11] loss: 0.007082\n",
      "[12] loss: 0.005642\n",
      "[13] loss: 0.004326\n",
      "[14] loss: 0.003098\n",
      "[15] loss: 0.002930\n",
      "[16] loss: 0.002193\n",
      "[17] loss: 0.001417\n",
      "[18] loss: 0.001157\n",
      "[19] loss: 0.001124\n",
      "[20] loss: 0.000870\n",
      "[21] loss: 0.000694\n",
      "[22] loss: 0.000626\n",
      "[23] loss: 0.000513\n",
      "[24] loss: 0.000428\n",
      "[25] loss: 0.000400\n",
      "[26] loss: 0.000341\n",
      "[27] loss: 0.000303\n",
      "[28] loss: 0.000267\n",
      "[29] loss: 0.000252\n",
      "[30] loss: 0.000233\n",
      "[31] loss: 0.000207\n",
      "[32] loss: 0.000194\n",
      "[33] loss: 0.000172\n",
      "[34] loss: 0.000161\n",
      "[35] loss: 0.000148\n",
      "[36] loss: 0.000134\n",
      "[37] loss: 0.000124\n",
      "[38] loss: 0.000113\n",
      "[39] loss: 0.000105\n",
      "[40] loss: 0.000094\n",
      "[41] loss: 0.000088\n",
      "[42] loss: 0.000082\n",
      "[43] loss: 0.000075\n",
      "[44] loss: 0.000070\n",
      "[45] loss: 0.000066\n",
      "[46] loss: 0.000061\n",
      "[47] loss: 0.000057\n",
      "[48] loss: 0.000053\n",
      "[49] loss: 0.000048\n",
      "[50] loss: 0.000044\n",
      "Finished Training\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T11:50:03.519789Z",
     "start_time": "2025-02-10T11:50:03.354702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = len(dataloader_test.dataset)\n",
    "\n",
    "    for (images, labels) in dataloader_test:\n",
    "        images = images.reshape(images.shape[0], 1, 28, 28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = conv_nn(images)\n",
    "\n",
    "        # max returns (output_value ,index)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the {n_samples} test images: {100*acc} %')"
   ],
   "id": "d2428712a12809e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.83999999999999 %\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T11:48:19.566154Z",
     "start_time": "2025-02-10T11:48:19.564197Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3b448532c958bc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x138c1d340>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T11:48:19.567903Z",
     "start_time": "2025-02-10T11:48:19.566609Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9813b989147645c4",
   "outputs": [],
   "execution_count": 112
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
