{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### This is a notebook to follow along the #21 lesson from \"Learn PyTorch. Become a Deep Learning Engineer. Get Hired.\" by Udemy",
   "id": "c1e6a44a2e02389d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:01.179450Z",
     "start_time": "2025-02-12T15:50:00.325830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np"
   ],
   "id": "17ce01474ada9c35",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:01.193129Z",
     "start_time": "2025-02-12T15:50:01.180390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = torch.tensor(\n",
    "    [\n",
    "        [[1, 2],\n",
    "         [3, 4],\n",
    "         [5, 6]],\n",
    "        [[7, 8],\n",
    "         [9, 10],\n",
    "         [11, 12]]\n",
    "     ]\n",
    ")\n",
    "a"
   ],
   "id": "7c8ad9149457c3db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2],\n",
       "         [ 3,  4],\n",
       "         [ 5,  6]],\n",
       "\n",
       "        [[ 7,  8],\n",
       "         [ 9, 10],\n",
       "         [11, 12]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:01.195151Z",
     "start_time": "2025-02-12T15:50:01.193658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shape, dim = a.shape, a.ndim\n",
    "print(shape, dim)"
   ],
   "id": "ce2136abe2a7a2dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2]) 3\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### To access data in a tensor, we can use Python slicing as per all of the other containers we met so far",
   "id": "8588f80b0ba3f2ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:01.198591Z",
     "start_time": "2025-02-12T15:50:01.196219Z"
    }
   },
   "cell_type": "code",
   "source": "a[0][1][1]",
   "id": "df898222664cb129",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:01.200892Z",
     "start_time": "2025-02-12T15:50:01.199142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#as we can see we are not accessing directly the scalar. we are getting back only a tensor object\n",
    "print(type(a[0][1][1]))\n",
    "#to access the scalar we have to pass through the function item()\n",
    "print('Type check: ', type(a[0][1][1].item()),' | Scalar value through item(): ', a[0][1][1].item())"
   ],
   "id": "4e778e9062589fe2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "Type check:  <class 'int'>  | Scalar value through item():  4\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Another interesting fact about tensors iin PyTorch is regarding the device you can mount them on:",
   "id": "284cf95bf182ca3c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:01.203033Z",
     "start_time": "2025-02-12T15:50:01.201304Z"
    }
   },
   "cell_type": "code",
   "source": "a.dtype",
   "id": "5042b46e13efcbcb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:01.233095Z",
     "start_time": "2025-02-12T15:50:01.203655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#We move the a tensor to our macbook GPU ('mps' is used to point to metal supported GPUs where available)\n",
    "#Moreover, we can set the dtype of the tensor, by means of the argument dtype\n",
    "\n",
    "#for both changing the device on which the tensor is on, and the dtype we use the function .to()\n",
    "a = a.to(dtype=torch.float16, device='mps')\n",
    "a.dtype"
   ],
   "id": "9b9be3813d49cce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:01.315547Z",
     "start_time": "2025-02-12T15:50:01.233707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Another way to deal with dtype is to use the .type()\n",
    "a = a.type(torch.uint8)\n",
    "a.dtype"
   ],
   "id": "f335b795c28dc06a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.uint8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### There is a parameter we can set on every tensor we create which holds the information about the gradient of a function / operation, with regards to that tensor we point out. <font color='red'>WARNING: </font> a gradient can only be calculated by means of the .backward() function, applied on a scalar value",
   "id": "244e4fc397976db7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:01.335799Z",
     "start_time": "2025-02-12T15:50:01.316072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([[1., -1.], [1., 1.]], requires_grad=True, dtype=torch.float16)\n",
    "y = torch.rand(size=(2,1), dtype=torch.float16)\n",
    "out = (x.pow(2) * y).sum()\n",
    "out.backward()\n",
    "x.grad"
   ],
   "id": "2b1c74707fede554",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0400, -0.0400],\n",
       "        [ 0.7051,  0.7051]], dtype=torch.float16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:01.446157Z",
     "start_time": "2025-02-12T15:50:01.337498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "B = torch.randn(size=(10, 3), dtype=torch.float16, device='mps') #it generates number from a STANDARD NORMAL distribution\n",
    "C = torch.rand(size=(3,1), #it generates number from a UNIFORM distribution ranging [0, 1) (every number as the same probability)\n",
    "               dtype=torch.float16, \n",
    "               device='mps')\n",
    "D = B @ C\n",
    "D"
   ],
   "id": "bb861de1b05348fd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0950],\n",
       "        [-1.2539],\n",
       "        [-0.3042],\n",
       "        [-0.3145],\n",
       "        [-2.1016],\n",
       "        [-0.9082],\n",
       "        [-0.4675],\n",
       "        [ 2.2480],\n",
       "        [-0.1793],\n",
       "        [-0.2212]], device='mps:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Just to talk about the most common methods to create tensors, we must list:\n",
    "* zeros\n",
    "* ones\n",
    "* zeros_like\n",
    "* ones_like"
   ],
   "id": "d318f1f10b9e5ec6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:01.451197Z",
     "start_time": "2025-02-12T15:50:01.446861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ZEROS = torch.zeros(size=(3,4))\n",
    "ONES = torch.ones(size=(3,4))\n",
    "ZEROS, ONES "
   ],
   "id": "20be4135254c00f8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:01.457217Z",
     "start_time": "2025-02-12T15:50:01.451908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ZEROS_LIKE = torch.zeros_like(input=D) #we set the size of this new tensor to be like the one of tensor named D\n",
    "ZEROS_LIKE"
   ],
   "id": "38c8bb7ab3075b98",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], device='mps:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### <font color='yellow'>NOTE: </font>the device of the new tensor created with zeros_like is the same of the input tensor (in this case D is on the mps)",
   "id": "6aa5999b32912acd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Some operations on tensors now...keeping in mind the general rules for the broadcasting:\n",
    "\n",
    "General semantics\n",
    "\n",
    "Two tensors are “broadcastable” if the following rules hold:\n",
    "\n",
    "Each tensor has at least one dimension.\n",
    "When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist."
   ],
   "id": "a41cadf34e67737f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:01.461387Z",
     "start_time": "2025-02-12T15:50:01.457724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "first_tensor = torch.randint(\n",
    "    low=0,\n",
    "    high=5,\n",
    "    size=(5, 3),\n",
    ")\n",
    "\n",
    "second_tensor = torch.randint(\n",
    "    low=0,\n",
    "    high=5,\n",
    "    size=(5, 1)\n",
    ")\n",
    "\n",
    "first_tensor, first_tensor.shape, second_tensor"
   ],
   "id": "6fd0f858dfbe5d1f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 0],\n",
       "         [3, 3, 2],\n",
       "         [3, 4, 3],\n",
       "         [3, 4, 2],\n",
       "         [0, 4, 1]]),\n",
       " torch.Size([5, 3]),\n",
       " tensor([[1],\n",
       "         [4],\n",
       "         [0],\n",
       "         [2],\n",
       "         [2]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:01.464Z",
     "start_time": "2025-02-12T15:50:01.461933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'The shape of first_tensor is {first_tensor.shape} | The shape of second_tensor is {second_tensor.shape}')\n",
    "print(f'The dtype of first_tensor is {first_tensor.dtype} | The dtype of second_tensor is {second_tensor.dtype}')"
   ],
   "id": "e4d50268daa12a65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of first_tensor is torch.Size([5, 3]) | The shape of second_tensor is torch.Size([5, 1])\n",
      "The dtype of first_tensor is torch.int64 | The dtype of second_tensor is torch.int64\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:01.466935Z",
     "start_time": "2025-02-12T15:50:01.464443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mul_tensor = torch.mul(input=first_tensor, other=second_tensor)\n",
    "mul_tensor.shape, mul_tensor"
   ],
   "id": "4510bb80badf7f22",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3]),\n",
       " tensor([[ 0,  0,  0],\n",
       "         [12, 12,  8],\n",
       "         [ 0,  0,  0],\n",
       "         [ 6,  8,  4],\n",
       "         [ 0,  8,  2]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Another important thing about the tensors is regarding the usage of the parameter axis in the aggregation operations, such as min, max, sum etc...\n",
    "#### axis must be set to an integer which stands for the dimension <font color='yellow'>WE WANT TO SQUEEZE</font>.\n",
    "#### e.g.: if we squeeze a dimension in a 3-dimensioned tensor and we are computing the minimum, then for all the values in that dimension the system will get the minimum value and will return a named tuple as follows: \n",
    "#### * the first term of the tuple will hold the content of the minimum for the given squeezed dimension of the tensor\n",
    "#### * the second term will hold the indices where those numbers where found in that same squeezed dimension "
   ],
   "id": "61b257024b96b8d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:01.470261Z",
     "start_time": "2025-02-12T15:50:01.467480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "min_tensor = torch.arange(start=0,\n",
    "                          end=80,\n",
    "                          step=2,\n",
    "                          ).reshape(2, 2, -1)\n",
    "min_tensor.shape"
   ],
   "id": "12b1f0bafbbb2ff3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:01.475277Z",
     "start_time": "2025-02-12T15:50:01.470963Z"
    }
   },
   "cell_type": "code",
   "source": "min_tensor.min(dim=0)",
   "id": "6102f02e035a4462",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor([[ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18],\n",
       "        [20, 22, 24, 26, 28, 30, 32, 34, 36, 38]]),\n",
       "indices=tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:01.478278Z",
     "start_time": "2025-02-12T15:50:01.476023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Just as a \n",
    "min_tensor"
   ],
   "id": "6e16f2db2b399d7a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18],\n",
       "         [20, 22, 24, 26, 28, 30, 32, 34, 36, 38]],\n",
       "\n",
       "        [[40, 42, 44, 46, 48, 50, 52, 54, 56, 58],\n",
       "         [60, 62, 64, 66, 68, 70, 72, 74, 76, 78]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Just to reinforce the example: here under we have the same applied to a .sum()",
   "id": "d70aae02e5c2bf9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:01.481054Z",
     "start_time": "2025-02-12T15:50:01.478845Z"
    }
   },
   "cell_type": "code",
   "source": "min_tensor.sum(dim=1)",
   "id": "672f77bc272f3e05",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 20,  24,  28,  32,  36,  40,  44,  48,  52,  56],\n",
       "        [100, 104, 108, 112, 116, 120, 124, 128, 132, 136]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### To close the topic regarding the min and max values, we can just pick the index where the min or max value lies, using argmin and argmax. \n",
    "#### The dim parameter behaves and affects the function return as per the other agrgegation functions."
   ],
   "id": "39cfb06d4bad36a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:01.484260Z",
     "start_time": "2025-02-12T15:50:01.481611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rand_tensor = torch.randint(\n",
    "    low=0,\n",
    "    high=100,\n",
    "    size=(3, 3, 2)\n",
    ")\n",
    "rand_tensor"
   ],
   "id": "9366611dee202576",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[14, 77],\n",
       "         [48, 76],\n",
       "         [74, 73]],\n",
       "\n",
       "        [[53, 28],\n",
       "         [80,  0],\n",
       "         [48,  6]],\n",
       "\n",
       "        [[88, 92],\n",
       "         [96, 37],\n",
       "         [74, 61]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:01.487468Z",
     "start_time": "2025-02-12T15:50:01.484898Z"
    }
   },
   "cell_type": "code",
   "source": "rand_tensor.argmax(dim=0)",
   "id": "c4803ee67bf84554",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2],\n",
       "        [2, 0],\n",
       "        [0, 0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Let's talk about stacking tensors together using <font color='orange'>torch.stack()</font>\n",
    "#### <font color='yellow'>FROM THE DOCS:</font>\n",
    "#### Concatenates a sequence of tensors along a new dimension.\n",
    "\n",
    "#### All tensors need to be of the same size.\n",
    "### The keyword is 'new dimension'. The effect of stack are very different from the stack we could expect to get back (which actually comes out from another foo, called torch.cat())\n"
   ],
   "id": "7f708dd063871b2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:20.346863Z",
     "start_time": "2025-02-12T15:50:20.343729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#let's create an example of tensor\n",
    "x = torch.arange(\n",
    "    start=0,\n",
    "    end=10,\n",
    ").reshape(2,5)\n",
    "y = torch.arange(\n",
    "    start=10,\n",
    "    end=20,\n",
    ").reshape(2,5)\n",
    "\n",
    "torch.stack(tensors=[x, y], dim=1)"
   ],
   "id": "f6d0413fc141aa5f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3,  4],\n",
       "         [10, 11, 12, 13, 14]],\n",
       "\n",
       "        [[ 5,  6,  7,  8,  9],\n",
       "         [15, 16, 17, 18, 19]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Let's talk about stacking tensors together using <font color='orange'>torch.cat()</font>\n",
    "#### .cat() concatenates a list of tensors in tensors=[] along a given dimenion dim\n"
   ],
   "id": "179bed1dd67ca170"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:51:26.874934Z",
     "start_time": "2025-02-12T15:51:26.870803Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cat(tensors=[x, y], dim=1)",
   "id": "ef95cfeb3908a066",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4, 10, 11, 12, 13, 14],\n",
       "        [ 5,  6,  7,  8,  9, 15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Let's see the effect of squeeze(), unsqueeze() and permute()",
   "id": "3f2af5d1340b6b6b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:54:13.753743Z",
     "start_time": "2025-02-12T15:54:13.749625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "del(x)\n",
    "x = torch.rand(size=(3,2,1,3))\n",
    "#squeeze() Returns a tensor with all specified dimensions of input of size 1 removed.\n",
    "y = torch.squeeze(input=x)\n",
    "x, y"
   ],
   "id": "aebdead68189ac86",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.7613, 0.3361, 0.1974]],\n",
       " \n",
       "          [[0.9290, 0.9620, 0.4837]]],\n",
       " \n",
       " \n",
       "         [[[0.9209, 0.4363, 0.2314]],\n",
       " \n",
       "          [[0.9512, 0.8960, 0.6021]]],\n",
       " \n",
       " \n",
       "         [[[0.2444, 0.6819, 0.3668]],\n",
       " \n",
       "          [[0.2913, 0.6518, 0.7237]]]]),\n",
       " tensor([[[0.7613, 0.3361, 0.1974],\n",
       "          [0.9290, 0.9620, 0.4837]],\n",
       " \n",
       "         [[0.9209, 0.4363, 0.2314],\n",
       "          [0.9512, 0.8960, 0.6021]],\n",
       " \n",
       "         [[0.2444, 0.6819, 0.3668],\n",
       "          [0.2913, 0.6518, 0.7237]]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:56:15.316058Z",
     "start_time": "2025-02-12T15:56:15.312208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#on the other hand unsqueeze() Returns a new tensor with a dimension of size one inserted at the specified position.\n",
    "del(x)\n",
    "x = torch.rand(size=(3,3))\n",
    "y = torch.unsqueeze(input=x,\n",
    "                    dim=1)\n",
    "x, y"
   ],
   "id": "ad3a6e4c525edd99",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6129, 0.3554, 0.0899],\n",
       "         [0.8250, 0.5126, 0.5973],\n",
       "         [0.2072, 0.7395, 0.5498]]),\n",
       " tensor([[[0.6129, 0.3554, 0.0899]],\n",
       " \n",
       "         [[0.8250, 0.5126, 0.5973]],\n",
       " \n",
       "         [[0.2072, 0.7395, 0.5498]]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T16:01:03.435606Z",
     "start_time": "2025-02-12T16:01:03.431932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#permute() Returns a view of the original tensor input with its dimensions permuted.\n",
    "#a view always shares memory with the initial input\n",
    "x = torch.arange(\n",
    "    start=0,\n",
    "    end=100,\n",
    "    step=2\n",
    ").reshape(2, 5, -1)\n",
    "y = torch.permute(input=x, dims=(2, 0, 1))\n",
    "x.shape, y.shape"
   ],
   "id": "580c9fa24ff40d06",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5, 5]), torch.Size([5, 2, 5]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e99e310d56dd9709"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T16:32:27.679923Z",
     "start_time": "2025-02-12T16:32:27.677016Z"
    }
   },
   "cell_type": "code",
   "source": "torch.mps.driver_allocated_memory()",
   "id": "755386d52412e9c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25424.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "213a1d446bfcaa00"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
